{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6a7698d9",
      "metadata": {},
      "source": [
        "## Resume Anonymization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60e691cd",
      "metadata": {},
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "import os\n",
        "from pathlib import Path\n",
        "os.environ[\"KAGGLEHUB_CACHE\"] = str(Path.cwd() / \"data\" / \"kagglehub\")\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "path = kagglehub.dataset_download(\"snehaanbhawal/resume-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "074cca60",
      "metadata": {},
      "outputs": [],
      "source": [
        "resume_df = pd.read_csv(path + \"/Resume/resume.csv\")\n",
        "resume_df.drop(columns=['ID', 'Resume_html'], inplace=True)\n",
        "resume_df.rename(columns={'Resume_str': 'resume'}, inplace=True)\n",
        "resume_df = resume_df[['Category', 'resume']]\n",
        "resume_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9d2a9c3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# resume_df.iloc[0].resume\n",
        "resume_df.Category.unique(), len(resume_df.Category.unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e328bae8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select 2 resume samples from each category\n",
        "sampled_resumes = pd.concat([resume_df[resume_df.Category == cat].sample(\n",
        "    2, random_state=42) for cat in resume_df.Category.unique()\n",
        "]).reset_index(drop=True)\n",
        "sampled_resumes.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7e2d7d3",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# create a subsample of 5 resumes for testing\n",
        "subsampled_resumes = resume_df.sample(2, random_state=42).reset_index(drop=True)\n",
        "subsampled_resumes.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09135a81",
      "metadata": {},
      "outputs": [],
      "source": [
        "[\n",
        "        {\"resume_id\": idx, \"resume_text\": text}\n",
        "        for idx, text in subsampled_resumes.resume.items()\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58da0b35",
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.utils.pipeline_utils import batch_process_resumes\n",
        "\n",
        "processed_resumes = batch_process_resumes(\n",
        "    sampled_resumes.resume,\n",
        "    country=\"Singapore\"\n",
        ")\n",
        "# add the processed resumes to sampled_resumes dataframe as new columns\n",
        "# for key in processed_resumes[0].keys():\n",
        "#     subsampled_resumes[key] = [dct[key] for dct in processed_resumes]\n",
        "# subsampled_resumes.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32e7c648",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(processed_resumes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "255d1343",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create empty columns in the dataframe for the new keys\n",
        "for key in processed_resumes[0].keys():\n",
        "    if key not in sampled_resumes.columns:\n",
        "        sampled_resumes[key] = None\n",
        "# Fill the new columns with the processed resume data\n",
        "for k in processed_resumes:\n",
        "    for key in processed_resumes[k].keys():\n",
        "        sampled_resumes.loc[sampled_resumes.index == k, key] = processed_resumes[k][key]\n",
        "sampled_resumes.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92aa51f1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the processed resumes to a new CSV file\n",
        "os.makedirs(\"data/processed\", exist_ok=True)\n",
        "sampled_resumes.to_csv(\"data/processed/resumes.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa60ae04",
      "metadata": {},
      "source": [
        "## Post-processing - Resume"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d721d751",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import re \n",
        "\n",
        "\n",
        "def clean_text(text):\n",
        "    # remove multiple newlines\n",
        "    text = re.sub(r'\\n+', '\\n', text)\n",
        "    # remove multiple spaces\n",
        "    text = re.sub(r' +', ' ', text)\n",
        "    # strip leading and trailing whitespace\n",
        "    text = text.strip()\n",
        "    # remove triple backticks and the word markdown\n",
        "    text = text.replace(\"```\", \"\").replace(\"markdown\", \"\")\n",
        "    # remove first and last newlines\n",
        "    text = text.lstrip('\\n').rstrip('\\n')\n",
        "    # replace Candidate Name with CANDIDATE NAME\n",
        "    text = text.replace(\"Candidate Name\", \"CANDIDATE NAME\")\n",
        "    return text\n",
        "\n",
        "\n",
        "resume_df = pd.read_csv(Path(\"data/processed/resumes.csv\"))\n",
        "resume_df['localized'] = resume_df['localized'].apply(clean_text)\n",
        "# drop resume, anonymized, and reformatted columns, rename localized to resume\n",
        "resume_df = resume_df.drop(columns=['resume', 'anonymized', 'reformatted']).rename(columns={'localized': 'resume'})\n",
        "resume_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea9fc1f4",
      "metadata": {},
      "source": [
        "## Job Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dad1ac10",
      "metadata": {},
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "os.environ[\"KAGGLEHUB_CACHE\"] = str(Path.cwd() / \"data\" / \"kagglehub\")\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"marcocavaco/scraped-job-descriptions\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.read_csv(path + \"/JD_data.csv\", index_col=0)\n",
        "df['description'] = df['description'].apply(lambda x: x[3:-3])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4461e52f",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(df['major_job'].unique(), len(df['major_job'].unique()))\n",
        "print(df.ISCO.unique(), len(df.ISCO.unique()))\n",
        "print(df['job'].value_counts())\n",
        "\n",
        "# for i in range(9):\n",
        "    # print(\" \".join(df.iloc[i].position.split(\" \")[:-1]),'\\t', df.iloc[i].job)\n",
        "    # print(df.iloc[i].description[3:-3].replace(\". \", \".\\n\"))\n",
        "    # print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ba8590d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample a random row per unique job\n",
        "sampled_jobs = df.groupby('job').apply(lambda x: x.sample(1, random_state=42)).reset_index(drop=True)\n",
        "sampled_jobs.rename(columns={'description': 'job_description', \n",
        "                             'job': 'job_type', \n",
        "                             'major_job': 'job_classification'}, inplace=True)\n",
        "sampled_jobs.drop(columns=['location', 'ISCO'], inplace=True)\n",
        "sampled_jobs.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dee0ad50",
      "metadata": {},
      "outputs": [],
      "source": [
        "d = sampled_jobs.iloc[0]\n",
        "print(d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4bd5183",
      "metadata": {},
      "outputs": [],
      "source": [
        "# from src.utils.pipeline_utils import job_pipeline\n",
        "\n",
        "# job_dct = job_pipeline(job_classification=d['job_classification'], \n",
        "#                        job_type=d['job_type'], \n",
        "#                        position=d['position'], \n",
        "#                        job_description=d['job_description'])\n",
        "# print(job_dct)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70a7192f",
      "metadata": {},
      "outputs": [],
      "source": [
        "subsampled_jobs = sampled_jobs.sample(2, random_state=42).reset_index(drop=True)\n",
        "subsampled_jobs.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4da2cce",
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.utils.pipeline_utils import batch_job_pipeline\n",
        "\n",
        "batch_results = batch_job_pipeline(sampled_jobs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be5015b0",
      "metadata": {},
      "outputs": [],
      "source": [
        "len(batch_results), list(batch_results.keys())[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c39c9d9d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add the processed job descriptions to the sampled_jobs dataframe as new columns\n",
        "for key in batch_results[list(batch_results.keys())[0]].keys():\n",
        "    if key not in sampled_jobs.columns:\n",
        "        sampled_jobs[key] = None\n",
        "# Fill the new columns with the processed job data\n",
        "for job_id in batch_results:\n",
        "    for key in batch_results[job_id].keys():\n",
        "        sampled_jobs.loc[sampled_jobs.index == int(job_id), key] = batch_results[job_id][key]\n",
        "sampled_jobs.drop(columns=['job_id'], inplace=True)\n",
        "sampled_jobs.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd344c05",
      "metadata": {},
      "outputs": [],
      "source": [
        "# save the sampled_jobs to a csv file\n",
        "import os\n",
        "import pandas as pd\n",
        "os.makedirs(\"data/processed\", exist_ok=True)\n",
        "sampled_jobs.to_csv(\"data/processed/sampled_jobs.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3019475f",
      "metadata": {},
      "source": [
        "## Post-processing - Job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87c59b9d",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re \n",
        "\n",
        "def clean_text(text):\n",
        "    # remove multiple newlines\n",
        "    text = re.sub(r'\\n+', '\\n', text)\n",
        "    # remove multiple spaces\n",
        "    text = re.sub(r' +', ' ', text)\n",
        "    # strip leading and trailing whitespace\n",
        "    text = text.strip()\n",
        "    # remove triple backticks and the word markdown\n",
        "    text = text.replace(\"```\", \"\").replace(\"markdown\", \"\")\n",
        "    # remove first and last newlines\n",
        "    text = text.lstrip('\\n').rstrip('\\n')\n",
        "    return text\n",
        "\n",
        "results_df = pd.read_csv(\"data/processed/sampled_jobs.csv\", index_col=0)\n",
        "results_df['company_criteria'] = results_df['company_criteria'].apply(clean_text)\n",
        "results_df['previous_hires'] = results_df['previous_hires'].apply(clean_text)\n",
        "results_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d5064a9",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b583c171",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "hiring-agent",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
